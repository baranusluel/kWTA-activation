{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kWTA Activation.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "91zwtdcmlJt6",
        "Cj7JBR-eeoJa"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aoz5yR4qOGl",
        "colab_type": "text"
      },
      "source": [
        "# Resisting Adversarial Attacks by kWTA Activation\n",
        "*ICLR Reproducibility Challenge*\n",
        "\n",
        "**CS4803/7643 Spring 2020 Final Project**\n",
        "\n",
        "By: Baran Usluel and Ilya Golod"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFoCO20m9l2U",
        "colab_type": "text"
      },
      "source": [
        "## Our Plan\n",
        "\n",
        "*Will delete this cell later. For now, linking some resources and our guiding plan (copied from proposal spreadsheet):*\n",
        "\n",
        "**Paper:** https://arxiv.org/abs/1905.10510\n",
        "\n",
        "**ICLR Submission Review:** https://openreview.net/forum?id=Skgvy64tvr\n",
        "\n",
        "**Paper's Github:** https://github.com/a554b554/kWTA-Activation\n",
        "\n",
        "**Project Summary:**\n",
        "\n",
        "Implement k-WTA activation function as described in Enhancing Adversarial Defense by k-Winners-Take-All @ ICLR 2020. Reproduce empirical results (test accuracy and adversarial robustness) across the different network architectures, training methods and adversarial attacks shown in the paper. Possibly test with unexplored environments as well.\n",
        "\n",
        "**Follow-up:**\n",
        "\n",
        "The k-WTA activation function will be implemented in PyTorch on pretrained models. The architecture models tested will include those in the paper (ResNet, DenseNet and Wide ResNet) and possibly additional relevant models (SqueezeNet, AlexNet, VGG and so on).\n",
        "\n",
        "The white-box attack model will be examined since this is the main focus of the original paper. Specifically the attacks to be considered are: vanilla gradient ascent (as already implemented in PS2), projected gradient descent, Deepfool, Carlini-Wagner, Momentum Iterative Method, and possibly other state-of-the-art gradient-based adversarial attacks by using the Foolbox library.\n",
        "\n",
        "Since we are using pretrained models, we will only consider attacks on regularly trained models and not explore adversarial training. Note that the authors claim similar improvements with k-WTA across various training methods.\n",
        "\n",
        "Finally, we will be using the CIFAR10 dataset for the image classification task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b45jcGoHOxKf",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUcHF0TpO7KH",
        "colab_type": "code",
        "outputId": "da67814b-57dd-409f-a2fe-e03bcb1bda32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# If using colab:\n",
        "# Mounts google drive folder so we can save/load files.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUVVE53sPOyW",
        "colab_type": "code",
        "outputId": "a69ba83b-d113-4e51-87d4-552a8ecd4f41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Note to team members:\n",
        "# If you get a 'No such file' error when you run this, go to your Google Drive,\n",
        "# find the CS4803 Project folder under Shared With Me, right-click and select\n",
        "# Add Shortcut To Drive. This will make the path accessible.\n",
        "DATA_DIRECTORY = \"gdrive/My Drive/CS4803 Project/\"\n",
        "import os\n",
        "print(os.listdir(DATA_DIRECTORY))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['models', 'data', 'kWTA Activation.ipynb']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FI558mq5q9mV",
        "colab_type": "code",
        "outputId": "01f4d527-f7fa-429e-a197-707beeb44ac5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as T\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# When running on a new colab runtime, will need to install foolbox\n",
        "# by uncommenting following line. After running, colab will instruct\n",
        "# you to restart runtime to fix a dependency issue.\n",
        "!pip install foolbox\n",
        "import foolbox\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import copy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: foolbox in /usr/local/lib/python3.6/dist-packages (3.0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from foolbox) (1.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.6/dist-packages (from foolbox) (3.7.4.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from foolbox) (46.1.3)\n",
            "Requirement already satisfied: GitPython>=3.0.7 in /usr/local/lib/python3.6/dist-packages (from foolbox) (3.1.1)\n",
            "Requirement already satisfied: eagerpy==0.27.0 in /usr/local/lib/python3.6/dist-packages (from foolbox) (0.27.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from foolbox) (1.18.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.6/dist-packages (from GitPython>=3.0.7->foolbox) (4.0.4)\n",
            "Requirement already satisfied: smmap<4,>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from gitdb<5,>=4.0.1->GitPython>=3.0.7->foolbox) (3.0.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-7I72lWnXnc",
        "colab_type": "code",
        "outputId": "154d6648-dd16-4053-b079-67f29c5037e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# For massive speed-up, ensure GPU is selected from Runtime -> Change runtime type.\n",
        "# Using hardware acceleration:\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
        "print(device)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WTGTzUf2QJx",
        "colab_type": "text"
      },
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5YtG509gPef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0Bz5fdDt1kq",
        "colab_type": "text"
      },
      "source": [
        "## k-WTA Activation Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0cTjMyvt57_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class kWTA(nn.Module):\n",
        "    def __init__(self, sr):\n",
        "        super(kWTA, self).__init__()\n",
        "        self.sr = sr\n",
        "\n",
        "    # Modified version of paper's forward implementation\n",
        "    def forward(self, x):\n",
        "        # Custom code to work with any array size:\n",
        "        tmpx = x.view(x.shape[0], -1)\n",
        "        size = tmpx.shape[1]\n",
        "        k = int(self.sr * size)\n",
        "        # Directly taken from paper's implementation:\n",
        "        topval = tmpx.topk(k, dim=1)[0][:,-1]\n",
        "        topval = topval.repeat(tmpx.shape[1], 1).permute(1,0).view_as(x)\n",
        "        comp = (x>=topval).to(x)\n",
        "        return comp*x\n",
        "\n",
        "    # TODO: Is there a more efficient way of computing this?\n",
        "\n",
        "    # # An alternate implementation:\n",
        "    # def forward(self, x):\n",
        "    #     tmpx = x.view(x.shape[0], -1)\n",
        "    #     size = tmpx.shape[1]\n",
        "    #     k = int(self.sr * size)\n",
        "    #     top_inds = tmpx.topk(k, dim=1)[1]\n",
        "    #     mask = torch.zeros_like(tmpx, dtype=torch.bool)\n",
        "    #     mask.scatter_(1, top_inds, True)\n",
        "    #     tmpx[~mask] = 0\n",
        "    #     return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2NHO7Bdz2eo",
        "colab_type": "code",
        "outputId": "da13057c-a86f-410a-eab9-e54e09ae1546",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "# Checking to make sure kWTA forward-pass implementation is correct\n",
        "kwta = kWTA(0.2)\n",
        "a = torch.rand(2,5,5)\n",
        "print(a)\n",
        "b = kwta.forward(a)\n",
        "print(b)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[0.5274, 0.8131, 0.3820, 0.1201, 0.7550],\n",
            "         [0.8282, 0.4326, 0.0728, 0.3812, 0.2239],\n",
            "         [0.4673, 0.8676, 0.6395, 0.7522, 0.1018],\n",
            "         [0.5127, 0.9647, 0.9863, 0.2825, 0.8240],\n",
            "         [0.8514, 0.5285, 0.8886, 0.3605, 0.8340]],\n",
            "\n",
            "        [[0.9750, 0.7317, 0.7390, 0.1291, 0.3586],\n",
            "         [0.2684, 0.5842, 0.8184, 0.7598, 0.4875],\n",
            "         [0.9605, 0.7321, 0.5830, 0.5548, 0.4230],\n",
            "         [0.0711, 0.9194, 0.9996, 0.9654, 0.6621],\n",
            "         [0.7179, 0.6827, 0.6336, 0.9441, 0.5302]]])\n",
            "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.8676, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.9647, 0.9863, 0.0000, 0.0000],\n",
            "         [0.8514, 0.0000, 0.8886, 0.0000, 0.0000]],\n",
            "\n",
            "        [[0.9750, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.9605, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.9996, 0.9654, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.9441, 0.0000]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wa_E4Brw8-n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Replaces given activation with specified kWTA activation function\n",
        "def activation_to_kwta(model, old_activation, sr=0.2):\n",
        "    for child_name, child in model.named_children():\n",
        "        if isinstance(child, old_activation):\n",
        "            setattr(model, child_name, kWTA(sr))\n",
        "        else:\n",
        "            activation_to_kwta(child, old_activation, sr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBEU0ns62FqL",
        "colab_type": "text"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpSa_SC_G499",
        "colab_type": "code",
        "outputId": "8fd759b3-98e3-4209-a75b-81acfa9d2b94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# NOTE on normalization values:\n",
        "# Paper uses mean=0 var=1 (no-op), so that's what we used below (for now).\n",
        "# But pytorch docs suggest mean=var=0.5, see https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
        "# And some sources claim other specific values:\n",
        "#   https://github.com/kuangliu/pytorch-cifar/issues/19\n",
        "#   https://github.com/kuangliu/pytorch-cifar/blob/master/main.py\n",
        "MEAN = 0\n",
        "VAR = 1\n",
        "INPUT_SIZE = 224\n",
        "# Same transforms as paper, except also resizing to 224x224 because that\n",
        "# is what torchvision models expect\n",
        "transform_train = T.Compose(\n",
        "    [T.RandomCrop(32, padding=4),\n",
        "     T.RandomHorizontalFlip(),\n",
        "     T.Resize(INPUT_SIZE),\n",
        "     T.ToTensor(),\n",
        "     T.Normalize((MEAN,MEAN,MEAN), (VAR,VAR,VAR))])\n",
        "transform_test = T.Compose(\n",
        "    [T.Resize(INPUT_SIZE),\n",
        "     T.ToTensor(),\n",
        "     T.Normalize((MEAN,MEAN,MEAN), (VAR,VAR,VAR))])\n",
        "\n",
        "trainset = datasets.CIFAR10(root=DATA_DIRECTORY+'data', train=True, download=True, transform=transform_train)\n",
        "trainloader = DataLoader(trainset, batch_size=16, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = datasets.CIFAR10(root=DATA_DIRECTORY+'data', train=False, download=True, transform=transform_test)\n",
        "testloader = DataLoader(testset, batch_size=16, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88o7a1bXyRqk",
        "colab_type": "text"
      },
      "source": [
        "## Load Saved Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GGcKxcXqtb_",
        "colab_type": "text"
      },
      "source": [
        "### Pretrained Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6VDjGntyQ8r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Change pretrained model download directory, so it doesn't\n",
        "# download every time the runtime restarts\n",
        "os.environ['TORCH_HOME'] = DATA_DIRECTORY + 'models/pretrained'\n",
        "\n",
        "# We have four types of models stored here:\n",
        "# - pretrained: Default models from pytorch, trained on ImageNet\n",
        "# - relu: Fine-tuned models for CIFAR10\n",
        "# - kwta_0_1: Models using kwta activation with sparsity=0.1 for CIFAR10\n",
        "# - kwta_0_2: Models using kwta activation with sparsity=0.2 for CIFAR10\n",
        "models = {'pretrained': {}, 'relu': {}, 'kwta_0_1': {}, 'kwta_0_2': {}}\n",
        "\n",
        "# Download and load pretrained models (trained for ImageNet dataset)\n",
        "models['pretrained']['resnet'] = torchvision.models.resnet18(pretrained=True)\n",
        "models['pretrained']['densenet'] = torchvision.models.densenet121(pretrained=True)\n",
        "models['pretrained']['wide_resnet'] = torchvision.models.wide_resnet50_2(pretrained=True)\n",
        "models['pretrained']['vgg'] = torchvision.models.vgg11(pretrained=True)\n",
        "models['pretrained']['alexnet'] = torchvision.models.alexnet(pretrained=True)\n",
        "models['pretrained']['squeezenet'] = torchvision.models.squeezenet1_1(pretrained=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqnljgSnqv0B",
        "colab_type": "text"
      },
      "source": [
        "### Our Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9b6SPMrq2g8",
        "colab_type": "code",
        "outputId": "6da9aa6f-039b-42ed-bb28-3b71570465db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "############################################################\n",
        "# These are the models that we have trained and saved.     #\n",
        "# Keep this list updated, along with EXPERIMENTAL RESULTS: #\n",
        "############################################################\n",
        "\n",
        "# Reference on finetuning models: https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n",
        "\n",
        "# Note that the models listed below have been trained manually\n",
        "# with the training code in the following cell, by changing the\n",
        "# learning rates manually across epochs.\n",
        "\n",
        "## AlexNet ReLU\n",
        "# Based off pretrained AlexNet.\n",
        "# Trained 2 epochs (lr=0.01) + 2 epochs (lr=0.001)\n",
        "# Test accuracy: 87.7%\n",
        "# Vanilla attack on 20 batches:\n",
        "#   Robustness Accuracy:  2 / 2880 = 0.06944444444444445 %\n",
        "# Foolbox attacks on 20 batches:\n",
        "#   PGD, Robustness Accuracy: 0 %\n",
        "#   Deepfool, Robustness Accuracy: 0 %\n",
        "models['relu']['alexnet'] = copy.deepcopy(models['pretrained']['alexnet'])\n",
        "models['relu']['alexnet'].classifier[-1].out_features = 10\n",
        "models['relu']['alexnet'].load_state_dict(torch.load(\n",
        "        DATA_DIRECTORY + 'models/relu/AlexNet.pth'))\n",
        "\n",
        "## AlexNet kWTA 0.2\n",
        "# Based off ReLU AlexNet trained for first 2 epochs.\n",
        "# Trained 1 epoch (lr=0.01) + 2 epochs (lr=0.001)\n",
        "# Test accuracy: 88.4%\n",
        "# Vanilla attack on 20 batches:\n",
        "#   Robustness Accuracy:  26 / 2880 = 0.9027777777777778 %\n",
        "# Foolbox attacks on 20 batches:\n",
        "#   PGD, Robustness Accuracy: 0 %\n",
        "#   Deepfool, Robustness Accuracy: 0 %\n",
        "models['kwta_0_2']['alexnet'] = copy.deepcopy(models['relu']['alexnet'])\n",
        "activation_to_kwta(models['kwta_0_2']['alexnet'], nn.ReLU, sr=0.2)\n",
        "models['kwta_0_2']['alexnet'].load_state_dict(torch.load(\n",
        "        DATA_DIRECTORY + 'models/kwta_0_2/AlexNet.pth'))\n",
        "\n",
        "## AlexNet kWTA 0.1\n",
        "# Based off kWTA 0.2 AlexNet trained for first 1 epoch.\n",
        "# Trained 1 epoch (lr=0.01) + 2 epochs (lr=0.001)\n",
        "# Test accuracy: 88.4%\n",
        "# Vanilla attack on 20 batches:\n",
        "#   Robustness Accuracy:  522 / 2880 = 18.125 %\n",
        "# Foolbox attacks on 20 batches:\n",
        "#   PGD, Robustness Accuracy: 0.9375 %\n",
        "#   Deepfool, Robustness Accuracy: 3.125 %\n",
        "models['kwta_0_1']['alexnet'] = copy.deepcopy(models['kwta_0_2']['alexnet'])\n",
        "activation_to_kwta(models['kwta_0_1']['alexnet'], kWTA, sr=0.1)\n",
        "models['kwta_0_1']['alexnet'].load_state_dict(torch.load(\n",
        "        DATA_DIRECTORY + 'models/kwta_0_1/AlexNet.pth'))\n",
        "\n",
        "\n",
        "## ResNet ReLU\n",
        "# Based off pretrained ResNet.\n",
        "# Trained 1 epoch (lr=0.01) + 2 epochs (lr=0.001)\n",
        "# Test accuracy: 92.9%\n",
        "# Vanilla attack on 20 batches:\n",
        "#   Robustness Accuracy:  0 / 2880 = 0.0 %\n",
        "# Foolbox attacks on 20 batches:\n",
        "#   PGD, Robustness Accuracy: 0 %\n",
        "#   Deepfool, Robustness Accuracy: 0 %\n",
        "models['relu']['resnet'] = copy.deepcopy(models['pretrained']['resnet'])\n",
        "models['relu']['resnet'].fc.out_features = 10\n",
        "models['relu']['resnet'].load_state_dict(torch.load(\n",
        "        DATA_DIRECTORY + 'models/relu/ResNet18.pth'))\n",
        "\n",
        "## ResNet kWTA 0.2\n",
        "# Based off ReLU ResNet trained for first 1 epoch.\n",
        "# Trained 3 epochs (lr=0.01) + 2 epochs (lr=0.001)\n",
        "# Test accuracy: 91.5%\n",
        "# Vanilla attack on 20 batches:\n",
        "#   Robustness Accuracy:  186 / 2880 = 6.458333333333333 %\n",
        "# Foolbox attacks on 20 batches:\n",
        "#   PGD, Robustness Accuracy: 0 %\n",
        "#   Deepfool, Robustness Accuracy: 47.1875 %\n",
        "models['kwta_0_2']['resnet'] = copy.deepcopy(models['relu']['resnet'])\n",
        "activation_to_kwta(models['kwta_0_2']['resnet'], nn.ReLU, sr=0.2)\n",
        "models['kwta_0_2']['resnet'].load_state_dict(torch.load(\n",
        "        DATA_DIRECTORY + 'models/kwta_0_2/ResNet18.pth'))\n",
        "\n",
        "## ResNet kWTA 0.1\n",
        "# Based off kWTA 0.2 ResNet trained for 5 epochs.\n",
        "# Trained 4 epochs (lr=0.01) + 2 epochs (lr=0.001)\n",
        "# Test accuracy: 85.7%\n",
        "# Vanilla attack on 20 batches:\n",
        "#   Robustness Accuracy:  207 / 2880 = 7.1875 %\n",
        "# Foolbox attacks on 20 batches:\n",
        "#   PGD, Robustness Accuracy: 0 %\n",
        "#   Deepfool, Robustness Accuracy: 48.75 %\n",
        "models['kwta_0_1']['resnet'] = copy.deepcopy(models['kwta_0_2']['resnet'])\n",
        "activation_to_kwta(models['kwta_0_1']['resnet'], kWTA, sr=0.1)\n",
        "models['kwta_0_1']['resnet'].load_state_dict(torch.load(\n",
        "        DATA_DIRECTORY + 'models/kwta_0_1/ResNet18.pth'))\n",
        "\n",
        "\n",
        "# TODO: kWTA seems to be slower than ReLU, training taking longer. Benchmark this."
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91zwtdcmlJt6",
        "colab_type": "text"
      },
      "source": [
        "## Training Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flduWRn9lJAu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Trains the model in-place, and saves after every epoch to save_path.\n",
        "# Only trains 1 epoch by default\n",
        "def train(model, save_path, lr=0.01, epochs=1):\n",
        "    model = model.to(device) # use CUDA\n",
        "    model.train()\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward\n",
        "            outputs = model(inputs)\n",
        "            # backward\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            # had to add clipping to fix exploding gradients:\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item() / 200\n",
        "            if i % 200 == 199:    # print every 200 mini-batches\n",
        "                print('[%d, %5d] loss: %.3f' %\n",
        "                      (epoch + 1, i + 1, running_loss))\n",
        "                running_loss = 0.0\n",
        "\n",
        "        # save checkpoint after every epoch\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "\n",
        "    print('Finished Training')\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rv0AsX0NmxDy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#################################################\n",
        "# WARNING:                                      #\n",
        "# This will overwrite existing saved model!     #\n",
        "#################################################\n",
        "#train(models['kwta_0_1']['resnet'], lr=0.001, epochs=1, save_path=DATA_DIRECTORY+'models/kwta_0_1/ResNet18_1.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Xkixwy9rmzY",
        "colab_type": "text"
      },
      "source": [
        "## Test Model Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0L-pmnCtnh0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test the model\n",
        "def test(net):\n",
        "    net = net.to(device)\n",
        "    net.eval()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the 10000 test images: %.1f %%' % (\n",
        "        100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrOD0Z5RpKcd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test(models['kwta_0_1']['resnet'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_x83TVSQNZFp",
        "colab_type": "text"
      },
      "source": [
        "## Attacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cj7JBR-eeoJa",
        "colab_type": "text"
      },
      "source": [
        "### Vanilla Gradient Ascent\n",
        "Code taken from Fooling Images problem in PS2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwRItsV94CmE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_fooling_image(X, target_y, model, max_iter=100, debug=True):\n",
        "    \"\"\"\n",
        "    Generate a fooling image that is close to X, but that the model classifies\n",
        "    as target_y.\n",
        "    Inputs:\n",
        "    - X: Input image; Tensor of shape (1, 3, 224, 224)\n",
        "    - target_y: An integer in the range [0, 1000)\n",
        "    - model: A pretrained CNN\n",
        "    Returns:\n",
        "    - X_fooling: An image that is close to X, but that is classifed as target_y\n",
        "    by the model.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Initialize our fooling image to the input image, and wrap it in a Variable.\n",
        "    X_fooling = X.clone()\n",
        "    X_fooling_var = Variable(X_fooling, requires_grad=True)\n",
        "\n",
        "    learning_rate = 10 # fixed learning rate\n",
        "    \n",
        "    for it in range(max_iter):\n",
        "    ##############################################################################\n",
        "    # Generate a fooling image X_fooling that the model will classify as #\n",
        "    # the class target_y. You should perform gradient ascent on the score of the #\n",
        "    # target class, stopping when the model is fooled. #\n",
        "    # When computing an update step, first normalize the gradient: #\n",
        "    # dX = learning_rate * g / ||g||_2 #\n",
        "    ##############################################################################\n",
        "        scores = model(X_fooling_var) # only one image\n",
        "        target_score = scores[:, target_y]\n",
        "        if debug:\n",
        "            print(\"Iteration: %d, Target Score: %d\" % (it, target_score.data))\n",
        "        if scores.argmax() == target_y:\n",
        "            break\n",
        "        target_score.backward()\n",
        "        image_grad = X_fooling_var.grad.data\n",
        "        dX = learning_rate * image_grad / image_grad.norm()\n",
        "        X_fooling_var.data += dX # gradient *ascent*, so adding not subtracting dX\n",
        "\n",
        "    X_fooling = X_fooling_var.data\n",
        "\n",
        "    return X_fooling, it"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwqo78BNinZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vis_fooling_img(X_orig, y_orig, X_fooling, target_y, class_names):\n",
        "    print(class_names[y_orig])\n",
        "    imshow(X_orig)\n",
        "\n",
        "    print(class_names[target_y])\n",
        "    imshow(X_fooling)\n",
        "    \n",
        "    print('Difference')\n",
        "    imshow(X_fooling - X_orig)\n",
        "    \n",
        "    print('Magnified difference (10x)')\n",
        "    imshow(10*(X_fooling - X_orig))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpVOO0etM5z5",
        "colab_type": "text"
      },
      "source": [
        "### Run attacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFZdHrR_NOVQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run adversarial attack on the model.\n",
        "# Data is loaded in batches of 16 images, argument `num_batches`\n",
        "# specifies how many batches to iterate over.\n",
        "# Argument `type` takes on values: `vanilla`, `pgd`, `deepfool`\n",
        "def attack(model_in, attack_type='vanilla', debug=False, num_batches=10):\n",
        "    # copying model so we can modify it\n",
        "    import copy\n",
        "    model = copy.deepcopy(model_in)\n",
        "    # transfer to GPU for CUDA\n",
        "    model = model.to(device)\n",
        "    # put into evaluation mode\n",
        "    model.eval()\n",
        "    # Not going to train the model, so don't compute gradients w.r.t. parameters.\n",
        "    # Using this instead of `with torch.no_grad()` because we still want gradients w.r.t. inputs.\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    \n",
        "    if debug:\n",
        "        print(model)\n",
        "\n",
        "    # variables to keep track of vanilla attack's stats\n",
        "    num_robust = 0 # count how many times model's prediction was still correct after attack\n",
        "    num_fooled = 0 # count how many time the attack succeeded with the target class\n",
        "    total = 0\n",
        "\n",
        "    # variables to keep track of foolbox attack's stats\n",
        "    robust_acc_sum = 0\n",
        "\n",
        "    # Adversarial attack loop:\n",
        "    for j, data in enumerate(testloader, 0):\n",
        "        if j >= num_batches:\n",
        "            break\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        if attack_type == 'vanilla':\n",
        "            # TODO: Try to parallelize batch processing instead of one at a time\n",
        "            for i in range(len(images)): # for each input image to attack\n",
        "                for target_idx in range(10): # for each target label\n",
        "                    # skip if attack target is already correct label\n",
        "                    if target_idx == labels[i]:\n",
        "                        continue\n",
        "                    # attempt to make a fooling image with vanilla gradient ascent attack\n",
        "                    X_fooling, num_iter = make_fooling_image(images[i].unsqueeze(0),\n",
        "                                                             target_idx, model, max_iter=20, debug=debug)\n",
        "                    # evaluate fooling image with the model\n",
        "                    scores = model(X_fooling)\n",
        "                    is_fooled = scores.data.max(1)[1][0] == target_idx\n",
        "                    is_robust = scores.data.max(1)[1][0] == labels[i]\n",
        "                    if debug:\n",
        "                        if is_fooled:\n",
        "                            print('Fooled model, iterations =', num_iter)\n",
        "                        else:\n",
        "                            print('Failed to fool model!')\n",
        "                        X_fooling = X_fooling.cpu()\n",
        "                        # Visualize fooling image and original image differences\n",
        "                        #vis_fooling_img(images[i].cpu(), labels[i], X_fooling.cpu().squeeze(), target_idx, classes)\n",
        "                    num_fooled += is_fooled\n",
        "                    num_robust += is_robust\n",
        "                    total += 1\n",
        "\n",
        "            # Print stats after every minibatch\n",
        "            print('[Minibatch: %d] Fooled: %d, Robust: %d, Total: %d' % (j+1, num_fooled, num_robust, total))\n",
        "\n",
        "        else:\n",
        "            fmodel = foolbox.PyTorchModel(model, bounds=(0,1))\n",
        "            # Paper uses l_inf metric for all attacks.\n",
        "            # Using parameters specified in paper's appendix D.1\n",
        "            if attack_type == 'pgd':\n",
        "                attack_fn = foolbox.attacks.LinfPGD(steps=40, random_start=True, abs_stepsize=0.003)\n",
        "            elif attack_type == 'deepfool':\n",
        "                attack_fn = foolbox.attacks.LinfDeepFoolAttack(steps=20, candidates=10)\n",
        "            #epsilons = [0.0, 0.001, 0.01, 0.03, 0.1, 0.3, 0.5, 1.0]\n",
        "            epsilons = [0.031] # value used in the paper\n",
        "            _, _, success = attack_fn(fmodel, images, labels, epsilons=epsilons)\n",
        "\n",
        "            robust_accuracy = 1 - success.double().mean(axis=-1)\n",
        "            robust_acc_sum += robust_accuracy\n",
        "            # Print stats after every minibatch\n",
        "            print('[Minibatch: %d] Accuracy: %f %%' % (j+1, 100*robust_accuracy.item()))\n",
        "    \n",
        "    if attack_type == 'vanilla':\n",
        "        print(\"Attacks Succeeded:\", num_fooled.item(), \"/\", total, \"=\", 100 * num_fooled.item() / total, \"%\")\n",
        "        print(\"Robustness Accuracy: \", num_robust.item(), \"/\", total, \"=\", 100 * num_robust.item() / total, \"%\")\n",
        "    else:\n",
        "        print(\"Robustness Accuracy: \", 100 * robust_acc_sum.item() / num_batches, \"%\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHam6BQpPwVL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attack(models['relu']['resnet'], attack_type='vanilla', num_batches=20, debug=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3F5UULNcZIBq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attack(models['kwta_0_2']['resnet'], attack_type='vanilla', num_batches=20, debug=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXACftB3UZOS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attack(models['kwta_0_1']['resnet'], attack_type='vanilla', num_batches=20, debug=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2FYgn0uUbu4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attack(models['relu']['resnet'], attack_type='pgd', num_batches=20, debug=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iH5hq2e2UeI8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attack(models['kwta_0_2']['resnet'], attack_type='pgd', num_batches=20, debug=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cC91wjZ7UfE1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attack(models['kwta_0_1']['resnet'], attack_type='pgd', num_batches=20, debug=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IfltWRhUfm6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attack(models['relu']['resnet'], attack_type='deepfool', num_batches=20, debug=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AYZ8LbNUhEN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attack(models['kwta_0_2']['resnet'], attack_type='deepfool', num_batches=20, debug=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgCsthxwUhP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attack(models['kwta_0_1']['resnet'], attack_type='deepfool', num_batches=20, debug=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqrhRDI1UngJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}